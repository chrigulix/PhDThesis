\chapter{Introduction}
1896, A. H. Becquerel, while experimenting with fluorescence in his laboratory, placed samples of potassium-uranyl on a photographic plate wrapped in black paper and put it into a dark drawer of his desk. After developing the plate he found that it was exposed within the outline of his sample \cite{HistoryOfRadioactivity}. So, he concluded that said sample must emit some sort of radiation invisible to the eye and thus he discovered radioactivity \cite{Radioactivity}, although this term was later introduced by M. S. and P. Curie in \cite{NameRadioactivity}. Two years later, in 1898, E. Rutherford saw two different particles participating in the uranium decay \cite{BetaDecayDiscovery}, he called them \textalpha- and \textbeta-particles. In 1900, Becquerel was able to identify the \textbeta-particles as cathode rays \cite{BetaIsElectron}, \ie electrons, since they show the same mass to charge ratio while travelling through a magnetic field. Then, in 1902, again Rutherford together with his student F. Stoddy published their paper in two parts titled: ``The Cause and Nature of Radioactivity'' \cite{NatureOfRadioactivity1, NatureOfRadioactivity2}. They showed that chemical elements undergoing radioactive decays (only \textalpha- and \textbeta-decay, as \textgamma-decay was not yet discovered), are thereby transformed into other elements. Their conclusion was:\\

\cite[\textit{
    The results that have so far been obtained, which indicate that the velocity of this reaction is unaffected by the conditions, makes it clear that the changes in question are different in character from any that have been before dealt with in chemistry. It is apparent that we are dealing with phenomena outside the sphere of known atomic forces. Radioactivity may therefore be considered as a manifestation of subatomic chemical change.}
]{NatureOfRadioactivity1}\\

This statement is remarkably accurate, for a time, when even the structure of the atom was still unknown. In the following years the consensus among physicists was that the decay products are already in some form present in the atom even before the decay. Said view did not change after Rutherford's discovery of the atomic structure \cite{RutherfordScattering}, but was now moved from the atom as a whole to the nucleus. Hence, it was believed that the electron, during a \textbeta-decay, would cause the nucleus to recoil in order to conserve energy and momentum. Such two-body decays would lead to a sharp peak in the energy spectrum of the electron at the mass difference of the nuclei before and after the decay, according to Einstein \cite{SpecialRelativity}. There was just one problem, this discrete spectrum was not observed; on the contrary, in 1911 experimental data hinted at a continuous \textbeta-spectrum~\cite{BetaSpectrum1}, with a maximum energy at the mass difference, which was confirmed in 1914 by J. Chadwick \cite{BetaSpectrum2}. These findings seemed to violate energy conservation and marked the impetus for the field of neutrino physics.

In 1930 a young physicist named Wolfgang Pauli, wrote an open letter to the attendees of a conference on Radioactivity in T\"ubingen, proposing a solution to this missing energy puzzle of \textbeta-decays:\\

\cite[ \textit{
    Dear Radioactive Ladies and Gentlemen,\\
    As the bearer of these lines, to whom I graciously ask you to listen, will explain to you in more detail, because of the "wrong" statistics of the N- and Li-6 nuclei and the continuous beta spectrum, I have hit upon a desperate remedy to save the "exchange theorem" of statistics and the law of conservation of energy. Namely, the possibility that in the nuclei there could exist electrically neutral particles, which I will call neutrons, that have spin $1/2$ and obey the exclusion principle and that further differ from light quanta in that they do not travel with the velocity of light. The mass of the neutrons should be of the same order of magnitude as the electron mass and in any event not larger than $0.01$ proton mass. - The continuous beta spectrum would then make sense with the assumption that in beta decay, in addition to the electron, a neutron is emitted such that the sum of the energies of neutron and electron is constant.} \lbrack ...\rbrack \\
\textit{But so far I do not dare to publish anything about this idea, and trustfully turn first to you, dear radioactive people, with the question of how likely it is to find experimental evidence for such a neutron if it would have the same or perhaps a 10 times larger ability to get through} \lbrack material\rbrack \textit{ than a gamma-ray.\\
    I admit that my remedy may seem almost improbable because one probably would have seen those neutrons, if they exist, for a long time. But nothing ventured, nothing gained, and the seriousness of the situation, due to the continuous structure of the beta spectrum, is illuminated by a remark of my honoured predecessor, Mr Debye, who told me recently in Brussels: "Oh, It's better not to think about this at all, like new taxes." Therefore one should seriously discuss every way of rescue.} \lbrack ...\rbrack \\
    \textit{signed W. Pauli}
    ]{PauliLetter}\\

Hence, the idea of neutral particle participating in \textbeta-decays was born, which Pauli named neutron. However, when the neutral nucleon (neutron), was discovered two years later, Pauli's proposed name would have caused confusion. Thus, in 1934 Enrico Fermi renamed the particle ``neutrino'' in his theoretical description of the \textbeta-decay \cite{FermiTheory}, the name it still bares today. With Fermi's work a first estimate for a neutrino interaction cross section was given for an energy $E$ in \si{\mega\electronvolt} as 
\begin{equation}\label{eq:ExpectedCrossSectionValue}
\sigma(\bar\nu_e + p \rightarrow e^+ + n) = 10^{-43}E^2 \si{\centi\metre\squared}, 
\end{equation}
an exceedingly small cross section \cite{Perkins}. Fermi further proposed a new force to be involved in neutrino interactions, later called the weak force.

The expected small cross section impeded a fast confirmation of the theory by experimental means. Nevertheless, F. Reines and C. L. Cowan proposed and built an experiment with the aim to directly measure neutrinos through the process of inverse \textbeta-decay
\begin{equation} \label{eq:InverseBetaDecay}
 \bar{\nu}_e + p \rightarrow n + e^{+}.
\end{equation}
They used a detector with cadmium chloride (\ce{CdCl2}) dissolved in water as a target, interlayered by liquid scintillator calorimeters \cite{NuDiscoveryDetector1,NuDiscoveryDetector2}. The detector was situated a couple of \SI{100}{\metre} from the core of a \SI{1000}{\mega\watt} nuclear reactor acting as a the antineutrino source. Then, in 1956, more than two decades after Pauli's proposal, the first neutrino interaction was finally discovered and consequently, the more than four decades old puzzle of the continuous \textbeta-spectrum was finally solved. Furthermore, they also measured the first electron antineutrino cross section at \SI{6.3e-44}{\centi\metre\squared} \cite{NuDiscovery1,NuDiscovery2}.

A further breakthrough in neutrino physics was reached in 1962 at Brookhaven National Laboratory (BNL), where a group around L. M. Lederman, M. Schwartz, and J. Steinberger used the \SI{15}{\giga\electronvolt} proton beam for the neutrino production. For this purpose, they let the protons strike a beryllium target, whereby mostly charged pions ($\pi^+ / \pi^-$) were produced. From there, the pions were given \SI{21}{\metre} of free flight to decay into a neutrino and a muon. After this decay distance, all remnants were absorbed in a \SI{13.5}{\metre} thick iron shield in front of the detector. The group chose a modular spark chamber design with the aluminium separators between each spark gap acting as the target material. In order to reduce backgrounds the beam coincidence was used as well as veto pads around the detector. They expected to observe the inverse \textbeta-decay and therefore \gls{em} showers, yet they predominantly saw muons produced in the detector. After ruling out all possible backgrounds they deduced that there are at least two kinds of neutrinos: a $\nu_{\mu}$ coupled to the muon and produced in pion decay, as well as a $\nu_e$ coupled to the electron and produced in nuclear \textbeta-decay \cite{NuMuDiscovery}. Thus, the muon neutrino was discovered. In fact, as they did not use a horn magnet in their pion beam, they saw $\nu_{\mu}$ and $\bar\nu_{\mu}$ in their detector, although they could not be distinguished. Since then, many experiments measured $\nu_{\mu}$ and $\bar\nu_{\mu}$ cross sections over a variety of energy spectra and many of these results are summarised in \cite{PDG2018}.

The last three decades saw an emergence of large scale neutrino detectors. These increased target masses enabled us to investigate these elusive particles in much greater detail and thus, lead to the discovery of neutrino oscillation by the experiments \gls{t2k} \cite{NuOscillationDiscovery} and \gls{sno} \cite{NuMixingDiscovery}. Neutrino oscillation, an idea developed around 1960 \cite{PMNSMatrix1,PMNSMatrix2}, describes the quantum mechanical phenomenon of neutrinos changing their flavour over time, \eg $\nu_\mu \to \nu_e$. These findings imply the presence of two mass squared differences which determine the oscillation frequency, and three mixing angles representing the flavour probability amplitude. All five of the aforementioned parameters have been measured to various degrees of uncertainty with the last mixing angle being measured by the Daya Bay experiment in 2012 \cite{NuTheta13Measurement}. Note, the mechanism which lends mass to neutrinos is not yet known and is thus beyond the \gls{sm}. Moreover, there are other open questions regarding neutrinos which go beyond the \gls{sm}: are neutrinos Majorana fermions \cite{MajoranaFermions}, what is the mass of the individual neutrinos, what is the order of those masses, and is there \gls{CP} violation in the lepton sector. The latter could be a part of the explanation as to why there is a matter-antimatter-asymmetry in the universe \cite{NuCPViolation}. \Gls{CP} violation in the lepton sector is introduced by phase shift, $\delta_\text{cp}$, to the neutrino mixing. In order to measure $\delta_\text{cp}$, the \gls{dune} is currently conceived \cite{DUNE1,DUNE2,DUNE3,DUNE4}. Besides $\delta_\text{cp}$, \gls{dune} also aims to determine the aforementioned neutrino mass ordering. \Gls{dune} is a long-baseline (\SI{1300}{\kilo\metre}) experiment in a $\nu_\mu$ accelerator neutrino beam and will be using argon as the target material. In fact, it will employ multiple \glspl{lartpc} which is the same detector technology utilised in MicroBooNE \cite{MicroBooNEDetector}, used for performing the measurements presented in this thesis. Moreover, MicroBooNE and \gls{dune} feature similar neutrino beam energies with a maximum of $\sim\SI{1}{\giga\electronvolt}$ and $\sim\SI{2}{\giga\electronvolt}$, respectively. Thus, it is evident that MicroBooNE can provide useful information for \gls{dune}.

The aforementioned $\delta_\text{cp}$ and mass ordering are only discernable by observing slight deviations between expected and measured interaction rates of various neutrino flavours. These expected rates depend \ia on modelled predictions provided by \gls{mc} simulations. Hence, modern high precision experiments, like \gls{dune}, rely on accurate neutrino interaction models to achieve their physics goals. Neutrino interaction models are well understood for low neutrino energies $E_\nu < \SI{100}{\kilo\electronvolt}$ where they interact through elastic scattering. At high energy scales of $E_\nu > \SI{100}{\giga\electronvolt}$, neutrino interactions are well described by the electro-weak theory, itself a part of the \gls{sm}, and a quantum field theory established by S. L. Glashow \cite{ElectroweakGlashow}, A. Salam \cite{ElectroweakSalam}, and S. Weinberg \cite{ElectroweakWeinberg} around 1960. Unfortunately, physical constraints do not allow for long-baseline experiments operating in the well understood neutrino energy ranges mentioned above. The most interesting neutrino phenomena are found at the medium-energy range from \SIrange{0.1}{10}{\giga\electronvolt} \cite{ProgressInNuMeasurements}. In this energy range, however, the interaction model predictions are rather poor. This is emphasised by the latest cross section measurements published by \gls{t2k} \cite{CrossSectionT2K}, MINERvA \cite{CrossSectionMinerva}, MiniBooNE \cite{AxialMassMiniBooNE}, and MicroBooNE \cite{MicroBooNEFirstCCInclPublished}. The reason for the low model quality at medium-energy range is found in the running coupling of the strong force (see chapter \ref{sec:Theory}). The running coupling does simply not allow for the theoretical description of the interactions of quarks in a nuclear bound state in the framework of the \gls{sm}. Therefore, effective theories and phenomenological descriptions are employed to model a neutrino's interaction with the target nucleus \cite{GenieGenerator,GenieTools}.

Said phenomenological models are generally derived from and improved by measurements, however, there are difficulties with this procedure. First of all, the neutrino can only be indirectly measured, \ie we only see the final states of the interaction when the products leave the target nucleus. Initial interactions are theoretically well understood, but the following interactions within the nuclei of the target material are lacking the desired precision. Moreover, many of the measurements, employed to improve the models, use different target materials, thus the models need to be extrapolated to different numbers of nucleons in a target nucleus. This is often achieved with theories from nuclear physics like the \gls{rfg} model \cite{ProgressInNuMeasurements}. Historically, many experiments tried to reconstruct the initial neutrino energy from the kinematics of the interaction's products with the goal of presenting the result as a single differential cross section of $E_\nu$, \ie $d\sigma/dE_\nu$. In the energy range between \SI{0.1}{\giga\electronvolt} and \SI{1}{\giga\electronvolt}, the neutrino energy was reconstructed using the \gls{ccqe} model \cite{NuQuasiElasticScattering} which was originally developed for neutrino-deuterium interactions. However, when extrapolated to larger nucleons, \gls{ccqe} measurements showed stark inconsistencies, culminating in MiniBooNE's ``\gls{ccqe} puzzle'', when they measured a much higher \gls{ccqe} cross section than earlier deuterium based experiments \cite{AxialMassMiniBooNE}. Presently, experiments with large target nuclei omit the \gls{ccqe} model and use \gls{fsi} analyses instead. The idea is to present cross sections or event rates of certain event topologies, \eg an event topology with a $\nu_\mu$ \gls{cc} interaction with no pions and one proton (CC0$\pi$1p) \cite{ProgressInNuMeasurements}. Such a topology is also used in this thesis, specifically, the $\nu_\mu$ \gls{cc} inclusive topology which is simply given by a neutrino interaction with a muon (no other constraints added). These topologies are then presented as a differential or double-differential cross section (or rate) as a function of lepton kinematics, \eg $d\sigma/dE_\mu$. Modellers and phenomenologists then use these kinematic distributions to improve their models. However, this leaves room for ambiguities, since many different nuclear interactions could result in similar final states. 

Another issue is posed by the fact that these modern measurements still rely on neutrino interaction models for background estimates and primary interaction determination. For instance, a modern $\nu_{\mu}$ beam feature various contaminants, mostly $\bar{\nu}_\mu$, $\nu_e$, and $\bar{\nu}_e$. The background estimates of these contaminants have to be modelled; the same is true for dirt events, \ie events with a \gls{Vertex} outside of the \gls{lartpc}. Hence, the model used by the experiment creeps into the measurement when unfolding the interaction rates into a cross section. This is then again used to improve the models themselves and it is easy to see how this could end up in a vicious circle. However, sophisticated reconstruction and selection algorithms are able to reduce said model creep by reducing the background significantly. Moreover, properly evaluating the systematic uncertainties of said models mitigates this problem further, albeit decreasing the measurement's accuracy. Another critical step of unfolding the data into a cross section is the process of eliminating detector effects in the measurement. For this reason, unfolding always entails a matrix inversion or a pseudo inversion. The cross section results are subject to statistical fluctuation because of the inversion, although the effect can be reduced by using elaborate methods the D'Agostini unfolding \cite{DAgostiniUnfolding}.

As described above, most neutrino experiments choose to transform the raw data into a cross section in order to ensure comparability with the various models. Nevertheless, there are other methods than unfolding and a rather novel one is the so-called forward-folding \cite{ForwardFoldingIdea}. The philosophy of the forward-folding is to leave the data as measured in the detector in form of a neutrino interaction rate. For comparison, the model is changed to represent the same form as the measured interaction rate. The aim is to introduce the detector effects (smearing) as well as the model dependent backgrounds at the model side of the comparison. This approach reduces the model dependency of the measurement to a minimum while being statistically advantageous \cite{ForwardFolding}. In my thesis, the forward-folding method introduced by T. Mettler \cite{CRTThomasPhD} is used in order to make comparisons between a $\nu_\mu$ \gls{cc} inclusive interaction rate on argon and various neutrino interaction models. This measurement is a MicroBooNE publication in progress and will mark the third peer reviewed $\nu_\mu$ \gls{cc} inclusive interaction result in \gls{lar} after ArgoneuT \cite{ArgoneutFirstCCInclusive} and the first MicroBooNE result \cite{MicroBooNEFirstCCInclPublished}.

For surface detectors like MicroBooNE, high cosmic-ray activity can be observed. MicroBooNE's detector technology, the \gls{lartpc}, is especially vulnerable for cosmic-ray background. Because of its relatively slow readout speed, cosmic events can drift into the apparent \gls{fv} of the detector and mimic a neutrino interaction. In this thesis I also show, how cosmic \textgamma-rays can influence MicroBooNE's \gls{lee} measurement. This is done with a simplified \gls{mc} study in chapter \ref{sec:CosmicRayGammaBackground}.

% Since then, countless experiments measured neutrino cross sections over a variety of energy spectra, many of these results are summarised in \cite{PDG2018}. Moreover, other neutrino properties were introduced and experimentally verified in the meantime: most notably flavor mixing and neutrino oscillation \cite{NuOscillationDiscovery,NuMixingDiscovery}. These new discoveries added many neutrino parameters to be measured with ever increasing accuracy. For this purpose, the corresponding experiments rely on reliable cross section models, in order to detect the tiniest of excesses or deficits of certain neutrino flavours (the same is true for new physics). Said models are generally derived from measurements, however, there are difficulties. First of all, the neutrino can only be indirectly measured, \ie we only see the final states of the interaction when the products leave the target nucleon. Initial interactions are theoretically well understood, but the following interactions within the nuclei of the target material are lacking the desired precision. In essence, the goal of a cross section measurement is to provide data points for the improvement of said nuclear interaction models. This leaves room for ambiguities, as many nuclear interactions could result in similar final states. 
% 
% Modern, high precision experiments rely on neutrino interaction models for background estimates and primary interaction determination. For instance, a modern $\nu_{\mu}$ beam feature various contaminants, mostly $\bar{\nu}_\mu$, $\nu_e$, and $\bar{\nu}_e$. The background estimates of these contaminants have to be modelled; the same is true for dirt events. Hence, the model used by the experiment creeps into the measurement when unfolding the interaction rates into a cross section. This is then again used to improve the models themselves and it is easy to see how this could end up in a vicious circle. However, sophisticated reconstruction and selection algorithms are able to reduce said model creep by reducing the background significantly. Moreover, properly evaluating the systematic uncertainties of said models mitigates this problem further, albeit decreasing the measurement's accuracy. An other critical step of unfolding the data into a cross section is the process of eliminating detector effects in the measurement. For this reason, unfolding always entails a matrix inversion or a pseudo inversion. The cross section results are subject to statistical fluctuation because of the inversion, although the effect can be reduced by using elaborate methods the D'Agostini unfolding \cite{DAgostiniUnfolding}.
% 
% As described above, most neutrino experiments choose to transform the raw data into a cross section in order to ensure comparability with the various models. Nevertheless, there are other methods than unfolding and a rather novel one is the so-called forward-folding \cite{ForwardFoldingIdea}. The philosophy of the forward-folding is to leave the data as measured in the detector in form of a neutrino interaction rate. For comparison, the model is changed to represent the same form as the measured interaction rate. The aim is to introduce the detector effects (smearing) as well as the model dependent backgrounds to the model side of the comparison. This approach reduces the model dependency of the measurement to a minimum while being statistically advantageous \cite{ForwardFolding}. In my thesis, the forward-folding method introduced by T. Mettler \cite{CRTThomasPhD} is used in order to make comparisons between a $\nu_\mu$ \gls{cc} inclusive event rate measurement in the MicroBooNE detector and various neutrino interaction models. 
% 
% For surface detectors like MicroBooNE, high cosmic-ray activity can be observed. MicroBooNE's detector technology, the \gls{lartpc}, is especially vulnerable for cosmic-ray background. Because of its relatively slow readout speed, cosmic events can drift into the apparent \gls{fv} of the detector and mimic a neutrino interaction. In this thesis it also shown, how cosmic \textgamma-rays can influence MicroBooNE's \gls{lee} measurement. This is done with a simplified cosmic \gls{mc} study in chapter \ref{sec:CosmicRayGammaBackground}.


% The design employed the so called delayed coincidence technique, which takes advantage of the different timings of the finale state particle's reactions. As described in \ref{eq:InverseBetaDecay} the finale state particles are positron ($e^+$) and neutrons ($n$). Of these two the $e^+$ first loses its momentum through ionisation, forms positronium with an electron ($e^-$) of the target material, and finally is annihilated into two photons (\textgamma). These two \textgamma-rays are then detected in the liquid scintillator layer of the detector. This whole annihilation process forms the fast component of Reines' and Cowan's detector and takes place in a time frame of the order of \SI{1e-9}{\second}. Further more said signal has an upper threshold of \SI{1.02}{\mega\electronvolt} (two electron masses) if the two \textgamma-rays are fully contained in the scintillator layers. The neutron however loses its energy through moderation, \ie transformation into thermal energy through multiple elastic collision with the hydrogen nuclei of water molecules. Finally, after losing a large portion of its momentum, the neutron is eventually captured by the cadmium in the target material. In this capturing process two more \textgamma-rays are produced which can be detected by the liquid scintillator layers. The described process occurs in a time frame of the order of \SI{1e-6}{\second}, a \num{1000} times slower than the $e^+$ signal. This delayed coincidence is only constituted by the time difference of the momentum deprivation processes between moderation and ionisation. Ultimately an event signature is given by two signals within a \SI{5}{\micro\second} time window \cite{NuDiscoveryDetector2}. The main backgrounds of said detector were given by cosmic rays and reactor neutrons, which could mimic such a delayed coincidence signal. Therefore the detector was located underground of the reactor building and furthermore completely enclosed by lead and paraffin.
%TODO Shorten the above and conbine with below 

% The fission fragment of the uranium fuel in the reactor are neutron-rich and in average undergo six \textbeta-decay processes per fission with an energy spectrum peaking at a couple of \SI{}{\mega\electronvolt}. Combined with the reactor's power and the distance this yielded a flux of the order of \SI{e13}{\per\centi\metre\squared \per\second} at the detector, which allowed to compensate the low cross section shown in \ref{eq:ExpectedCrossSectionValue}. The observed reaction rate amounted to a few events per hour and consequently Reines and Cowan discovered the electron anti-neutrino \cite{NuDiscovery1,NuDiscovery2}. More than two decades after Pauli's proposal the neutrino was discovered and thus the more than four decades old puzzle of the continuous \textbeta-spectrum was finally solved.

%TODO describe oscillation (in short) and why microboone was conceived...
%TODO MiniBooNE cross section riddle and why forwardfolded

%TODO Get rid of everything below here!

% Also in 1956 T.D. Lee and C.N. Yang, reviewing experimental data, suspected that weak interactions are not invariant under spatial inversion, \ie they do not conserve parity \cite{Perkins, ParityLeeYang}. One year later C.S. Wu proofed Lee's and Yang's suspicion in a remarkable experiment. Said experiment used a supercooled sample of \ce{^{60}Co} at \SI{0.01}{\kelvin} inside a magnetic field. This caused a high proportion of the \ce{^{60}Co} nuclei to align their spin parallel to the magnetic field lines. As a result the \textbeta-electrons were not decaying isotropically in all directions but preferably in one direction, \ie against the magnetic field vector. This proofed the parity violating nature of weak interactions \cite{ParityWu}.
%TODO Drawing of spin-momentum dependence of neutrinos
%TODO ? Write more on Wu.

% A further breakthrough in neutrino physics was reached in 1962 at Brookhaven National Laboratory (BNL), where a group around L. M. Lederman, M. Schwartz, and J. Steinberger used the \SI{15}{\giga\electronvolt} proton beam of the Alternating Gradient Synchrotron (AGS) for the neutrino production, which by itself marks a notable achievement. For that they let the protons strike a beryllium target whereby mostly charged pions ($\pi^+ / \pi^-$) were produced. From there the pions are moving in the general direction of the incident proton beam towards the detector an were given \SI{21}{\metre} of free flight to decay into a neutrino and a muon. After this decay distance all remnants were absorbed in a \SI{13.5}{\metre} iron shield in front of the detector. The group chose a modular spark chamber design with the aluminium separators of each spark gap acting as the target material. In order to reduce backgrounds the beam coincidence was used as well as veto pads around the detector. They expected to observe the inverse \textbeta-decay and therefore electro-magnetic (EM) showers, yet they predominantly saw muons produced in the detector. After ruling out all possible backgrounds they deduced that there are at least two kinds of neutrinos: a $\nu_{\mu}$ coupled to the muon and produced in pion decay, as well as a $\nu_e$ coupled to the electron and produced in nuclear \textbeta-decay \cite{NuMuDiscovery}. Thus the muon neutrino was discovered and in fact since they did not use a horn magnet in their pion beam, they saw $\nu_{\mu}$ and $\bar\nu_{\mu}$ in their detector, though they couldn't be distinguished.

% The discovery of a new type of neutrino sparked many new theories of their nature. Noteworthy are the works of Maki, Nakagawa, Sakata...
%TODO 1962 Maki, Nakagawa, Sakata mixing

%TODO ? 1953 Lepton number introduced
%TODO ? 1957 Pontecorvo nutrino-antineutrino oscillation like with kaons
%TODO 1967 Homestake solar neutrinos davis
%TODO ? 1975 Tau lepton Perl at SLAC
%TODO YEAR? LEP finds 3 neutrino lighter than 45 GeV.
%TODO 2000 nu_tau discovery DONuT at FNAL
%TODO 2002? SNO conferms mixing
%TODO OPERA and T2K results
